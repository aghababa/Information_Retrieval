\documentclass[11pt]{article}

\usepackage{pgfplots}
\pgfplotsset{compat=1.12}
\newtheorem{define}{Definition}
%\newcommand{\Z}{{\mathbb{Z}}}
%\usepackage{psfig}
\usepackage{tikz}
\usetikzlibrary{arrows, automata}
\oddsidemargin=0.15in
\evensidemargin=0.15in
\topmargin=-.5in
\textheight=9in
\textwidth=6.25in
\usepackage{latexsym,bm}
\usepackage{amsmath}
\usepackage{amsfonts}%for math
\usepackage{graphicx}%for eps
\usepackage{url}


\newif\ifgrading

\gradingtrue
%\gradingfalse

\begin{document}
\input{preamble.tex}

\assignment{3}{}{u1255635}{Hasan Pourmahmoodaghababa}

\baselineskip = 5mm

%\input{answers}

\section*{Ranking Features}%

\begin{itemize}
\item Query-document matching features: sum of tf$*$idf, mean of term frequency, BM25.
\item Document quality features: QualityScore, QualityScore2.
\item User behavior features: url dwell time, url click count, Query-url click count.
\end{itemize}
About which type of features are expected to be most useful in practice, I think it depends on many things like the query and the intend of user. 
\begin{itemize}
\item There are cases that query-document matching features are expected to be most useful in practice (like when we are searching for the query "Facebook"). 
\item There are cases that document quality features are very important (for example, when one searches for an app to install on his/her machine. In this case the quality of a web becomes essential).
\item In other situations like searching for an ambiguous query (probably like "Java") with more than one meaning, in addition to query-document matching features, user behavior features also can be effective to help semantic matching. 
\end{itemize}

%It seems that Query-document matching features are expected to be most useful in practice as more than $90\%$ of features are of this type which shows their importance. 



\section*{Ranking Models}%

\begin{itemize}
\item SVMrank: Pairwise
\item RankNet: Pairwise
\item MART: Pointwise
\item LamdbaMART: Listwise
\end{itemize}
For nDCG@5 I got the following values:
\begin{itemize}
\item SVMrank: 0.2975 (using linear normalization and sorted data by qid. I wrote a code in python to calculate nDCG@5 from predictions generated by SVMrank for test data.)
\item RankNet: 0.2893 (using zscore normalization, 1 layer, 5 nodes and learning rate of 0.00001)
\item MART: 0.4294 (using linear normalization)
\item LamdbaMART: 0.4311 (using linear normalization)
\end{itemize}
LamdbaMART outperformed other models here. I think the reason is that it is a listwise method and thus is based on ranking metrics (like MAP, nDCG) on list level. Therefore, to maximize ranking performance, this model tries to optimize the ranking list directly. However, in pointwise and pairwise models the loss functions we try to optimize are not the ranking metrics. Therefore, it is expected to get a better performance with listwise models like LamdbaMART than pointwise and pairwise models like SVMrank, RankNet and MART. 












\end{document}
